import os
import tensorflow as tf

# ğŸ“Œ Ruta del modelo Keras previamente entrenado
model_path = "char_recognizer_model_ffnn.keras"

# Verifica si el modelo existe antes de cargarlo
if not os.path.exists(model_path):
    raise FileNotFoundError(f"âŒ No se encontrÃ³ el archivo del modelo: {model_path}")

# ğŸ”¹ Cargar el modelo Keras entrenado
model = tf.keras.models.load_model(model_path)
print("âœ… Modelo Keras cargado correctamente.")

# ğŸ“Œ FunciÃ³n para guardar modelos TFLite de manera segura
def save_tflite_model(tflite_model, filename):
    """
    Guarda el modelo en formato TFLite solo si no existe previamente.

    ParÃ¡metros:
    - tflite_model: Modelo convertido a formato TensorFlow Lite.
    - filename: Nombre del archivo donde se guardarÃ¡ el modelo.
    """
    if os.path.exists(filename):
        print(f"âš ï¸ Omitiendo {filename}, ya existe un archivo con ese nombre.")
    else:
        with open(filename, "wb") as f:
            f.write(tflite_model)
        print(f"âœ… Modelo guardado: {filename}")

# ğŸ”¹ ConversiÃ³n estÃ¡ndar a TensorFlow Lite (precisiÃ³n Float32)
print("ğŸ”¹ Convirtiendo a TFLite (Float32)...")
converter = tf.lite.TFLiteConverter.from_keras_model(model)  # Crear conversor
tflite_model = converter.convert()  # Convertir modelo
save_tflite_model(tflite_model, "char_recognizer_model_ffnn.tflite")  # Guardar

# ğŸ”¹ ConversiÃ³n a TensorFlow Lite con cuantizaciÃ³n en Float16
# Beneficios: Reduce el tamaÃ±o del modelo, mantiene buena precisiÃ³n.
print("ğŸ”¹ Convirtiendo a TFLite (cuantizaciÃ³n Float16)...")
converter = tf.lite.TFLiteConverter.from_keras_model(model)  # Nuevo conversor
converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Activar optimizaciones
converter.target_spec.supported_types = [tf.float16]  # CuantizaciÃ³n en 16 bits
tflite_fp16_model = converter.convert()  # Convertir modelo
save_tflite_model(tflite_fp16_model, "char_recognizer_model_ffnn_fp16.tflite")  # Guardar

# ğŸ“Œ Mensaje final con los modelos generados
print("ğŸ¯ Â¡ConversiÃ³n completada!")
print("âœ… Modelos generados:")
print("- char_recognizer_model_ffnn.tflite (Float32)")
print("- char_recognizer_model_ffnn_fp16.tflite (Cuantizado en Float16)")
